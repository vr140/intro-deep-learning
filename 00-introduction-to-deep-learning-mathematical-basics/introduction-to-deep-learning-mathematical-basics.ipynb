{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Introduction to Deep Learning Mathematical Basics\n",
    "\n",
    "### 1. Mathematical Concepts\n",
    "\n",
    "Below we will cover the basic mathematical concepts of deep learning. I've tried to cover as minimal as possible to get you feeling familiar with the notation and rules involved.\n",
    "\n",
    "\n",
    "**NOTE: You do not have to learn all of this math in order to be successful at deep learning. I encourage you to skip to the next notebook and come back here. The math is useful to understand gradient descent and regularization in this notebook and backpropagation in the next notebook. Also, if you take time to understand, it will get you feeling comfortable enough to read deep learning posts and possibly even academic papers for new ideas.**\n",
    "\n",
    "#### 1.1 Vectors and Matrices\n",
    "\n",
    "A _vector_ is technically defined as something that has a magnitude and direction (in contrast to a _scalar_, which is just a number and only has magnitude). For the purposes of this notebook, a vector will represent a vertical _array_ of items, with dimensions m x 1 (or m rows and 1 column):\n",
    "\n",
    "$\\boldsymbol{x} = \\begin{bmatrix} \n",
    "x_{1} \\\\ \n",
    "x_{2} \\\\ \n",
    "... \\\\\n",
    "x_{m} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Notice we said \"items.\" An item could be a number, a variable, a function, anything... For now, think of these as scalars (eg x = [1,2,3]). **Just remember that a vector is just a data structure and it can contain whatever we want inside of it to suit our particular needs. You can have a vector of scalars, vector of variables, vector of functions, and even vector of vectors!**\n",
    "\n",
    "Note that the vector notation we use is a bolded $\\boldsymbol{x}$ (you may also see $\\vec{v}$ or $\\hat{v}$ but we will avoid those forms).  In contrast, a non-bolded x will represent a scalar (eg x = 6). If we wanted a horizontal array, we would write it as:\n",
    "\n",
    "$\\boldsymbol{x}^{T} = \\begin{bmatrix} \n",
    "x_{1} x_{2} ... x_{m}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "A capitalized bolded $\\boldsymbol{X}$ represents a _matrix_, which in our case will be used to represent a two dimensional m x n object, with m rows and n columns:\n",
    "\n",
    "$\\boldsymbol{X} = \\begin{bmatrix} \n",
    "x_{1,1} & x_{1,2} & ... & x_{1,n} \\\\ \n",
    "x_{2,1} & x_{2,2} & ... & x_{2,n} \\\\ \n",
    "... \\\\\n",
    "x_{m,1} & x_{m,2} & ... & x_{m,n} \n",
    "\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Derivatives\n",
    "\n",
    "\n",
    "Before we get to derivatives of vectors and matrices, let's talk about single variable derivative rules. if you feel like you need a review basic single variable derivative rules check out the videos in:\n",
    "https://www.khanacademy.org/math/old-ap-calculus-ab/ab-derivative-rules\n",
    "\n",
    "You can also see https://www.khanacademy.org/math/differential-calculus/dc-diff-intro for more rules. \n",
    "\n",
    "Below are the basic  derivative rules if you just need a reference:\n",
    "<img src=\"scalar_derivative_rules.jpg\" width=\"600\" height=\"480\" />\n",
    "\n",
    "\n",
    "The below explains how to think of the derivative d/dx. It seems scary but it's no different than + or * because it is just another operator:\n",
    "<img src=\"d_dx.jpg\" width=\"600\" height=\"480\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Gradient\n",
    "\n",
    "In the above rules, the function was a paramater of a single variable x. How we compute derivatives if there are multiple parameters (say x,y)? Well, it turns out we can only compute a _partial derivative_ with respect to one variable at a time. The notation used for partial derivative will be the following:\n",
    "<p>\n",
    "$\\frac{\\partial f(x,y)}{\\partial x}$ - partial derivative of f(x,y) with respect to x\n",
    "<p>\n",
    "$\\frac{\\partial f(x,y)}{\\partial y}$ - partial derivative of f(x,y) with respect to y\n",
    "<p>\n",
    "\n",
    "\n",
    "Using the example in [9], let's say $f(x,y) = 3x^{2}y$\n",
    "\n",
    "To get $\\frac{\\partial f(x,y)}{\\partial x}$ , we have to treat y as a constant and use the single variable derivative rules:\n",
    "\n",
    "\n",
    "$\\frac{\\partial f(x,y)}{\\partial x} = 6yx$\n",
    "\n",
    "Similarly, to get $\\frac{\\partial f(x,y)}{\\partial y}$ , we have to treat x as a constant and use the single variable derivative rules:\n",
    "\n",
    "\n",
    "$\\frac{\\partial f(x,y)}{\\partial y} = 3x^{2}$\n",
    "\n",
    "When you see the word _gradient_, remember that the gradient is a vector. Specifically, it's a vector of the partial derivatives of a function (\"vector of partials\" for short).\n",
    "\n",
    "$\\Large\\nabla f(x,y) = \\begin{bmatrix}\n",
    "\\frac{\\partial f(x,y)}{\\partial x}, \\frac{\\partial f(x,y)}{\\partial y}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "**What if we have multiple functions?**\n",
    "\n",
    "Let's say you also had another function $g(x,y) = 2x + y^{8}$ in addition to f(x,y) defined above.\n",
    "Then you stack the gradients in a matrix called the _Jacobian_ (we use the notation J for the Jacobian):\n",
    "\n",
    "<img src=\"simple_jacobian.jpg\" width=\"600\" height=\"480\" />\n",
    "\n",
    "That's a sample of matrix calculus!\n",
    "\n",
    "**What if we have a lot of parameters in each of our functions?**\n",
    "\n",
    "In the case of two parameters, we can manually write out the gradient for the function and consequently the Jacobian of multiple functions. However, we need a way to generalize this to a lot of parameters because neural networks often have a lot of parameters (eg weights). \n",
    "\n",
    "Let's say you had a function with many parameters $f(a,b,c...)$. We can rewrite it as $f(\\boldsymbol{x})$ (remember the bold symbol means a vector) where\n",
    "\n",
    "$\\boldsymbol{x} = \\begin{bmatrix} \n",
    "a \\\\ \n",
    "b \\\\ \n",
    "c \\\\ \n",
    "... \\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "which can be rewritten as:\n",
    "\n",
    "$\\boldsymbol{x} = \\begin{bmatrix} \n",
    "x_{1} \\\\ \n",
    "x_{2} \\\\ \n",
    "x_{3} \\\\ \n",
    "... \\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "NOTE: A initially confusing part may be that in the previous section, each of the elements in the vector (x1, x2, x3) represented a scalar (or number) whereas now each of these elements is actually a variable. \n",
    "\n",
    "Now, we can write our gradient of the vector valued function $f(\\boldsymbol{x})$ as:\n",
    "\n",
    "$\\Large\\nabla f(\\boldsymbol{x}) = \\begin{bmatrix}\n",
    "\\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{1}}, \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{2}}, \\frac{\\partial f(\\boldsymbol{x})}{\\partial x_{3}}, ...\n",
    "\\end{bmatrix}$\n",
    "\n",
    "**What if we have multiple functions, each with lots of parameters?**\n",
    "\n",
    "If we have multiple functions, $f_{1}$, $f_{2}$, ..., then we can use the Jacobian to get all the gradients! The Jacobian is just a stack of gradients.\n",
    "\n",
    "We can define a vector of functions $\\boldsymbol{y}$ as:\n",
    "\n",
    "$\\boldsymbol{y} = \\begin{bmatrix} \n",
    "f_{1}(\\boldsymbol{x}) \\\\ \n",
    "f_{2}(\\boldsymbol{x}) \\\\ \n",
    "f_{3}(\\boldsymbol{x}) \\\\ \n",
    "... \\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\Large\n",
    "J = \\frac{\\partial \\boldsymbol{y}}{\\partial \\boldsymbol{x}}\n",
    "$\n",
    "\n",
    "The Jacobian matrix is a stack of m × n possible partial derivatives where m = number of functions in the vector $\\boldsymbol{y}$ and n = number of variables in the vector $\\boldsymbol{x}$.\n",
    "\n",
    "<img src=\"complex_jacobian.jpg\" width=\"600\" height=\"480\" />\n",
    "\n",
    "**Can we summarize all this?**\n",
    "\n",
    "<p>\n",
    "For a function with a single variable $f(x)$, we use the derivative rules.\n",
    "<p>\n",
    "For a function with two variables $f(x, y)$, we use the partial derivative rules to make a gradient (vector of all the partial derivatives)\n",
    "<p>\n",
    "For two functions with two variables $f(x,y)$ and $g(x,y)$, we use the Jacobian to stack the two gradients.\n",
    "<p>\n",
    "For a function with n variables $f(\\boldsymbol{x})$, we use the partial derivative rules to make a gradient (vector of all the partial derivatives).\n",
    "<p>\n",
    "For m functions with n variables $\\boldsymbol{y}(\\boldsymbol{x})$, we use the Jacobian to stack the m gradients (each of which has npartials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 Chain Rule\n",
    "\n",
    "Good news! We don't have to learn another rule. We just have to know that such a thing as the \"chain rule\" exists (you can look it up if you'd like using [9] and [10] or Khan academy videos above).  \n",
    "\n",
    "The chain rule is what allows us to get the derivative of a function wrapping a single variable function:\n",
    "<p>\n",
    "$ y = f(g(x))$<p>\n",
    "$ u = g(x)$<p>\n",
    "$ y = f(u)$<p>\n",
    "\n",
    "and the derivatives of a function wrapping a vector of single variable functions $\\boldsymbol{g} = (u1, u2...)$\n",
    "<p>\n",
    "$ y = f(\\boldsymbol{g}) $\n",
    "\n",
    "\n",
    "and the derivatives of a vector of functions wrapping a vector of single variable functions:\n",
    "<p>\n",
    "$ y = \\boldsymbol{f}(\\boldsymbol{g}(x))$ :\n",
    "\n",
    "and the derivatives of a vector of a vector of functions wrapping a vector of single variable functions:\n",
    "<p>\n",
    "$\\boldsymbol{y} = \\begin{bmatrix} \n",
    "f_{1}(\\boldsymbol{g}(x)) \\\\ \n",
    "f_{2}(\\boldsymbol{g}(x)) \\\\ \n",
    "f_{3}(\\boldsymbol{g}(x)) \\\\ \n",
    "... \\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "and the partial derivatives of a vector of a vector of functions wrapping a vector of vector-valued functions (notice the bolded x):\n",
    "<p>\n",
    "$\\boldsymbol{y} = \\begin{bmatrix} \n",
    "f_{1}(\\boldsymbol{g}(\\boldsymbol{x})) \\\\ \n",
    "f_{2}(\\boldsymbol{g}(\\boldsymbol{x})) \\\\ \n",
    "f_{3}(\\boldsymbol{g}(\\boldsymbol{x})) \\\\ \n",
    "... \\\\ \n",
    "\\end{bmatrix}$\n",
    "\n",
    "**What's the punchline?**\n",
    "\n",
    "With neural networks, sometimes it works out where the expressions are this complicated. BUT not to worry! Using the combination of chain rules and scalar derivative rules and vector addition rules (not discussed here but mentioned in [9]), **deep learning libraries do all the differentiation for us**. \n",
    "<p>\n",
    "\n",
    "If you follow the  breakdown of the mathematics in [9], we can decompose any derivative using something known as the _vector chain rule_, which reduces to a matrix multiplication where each matrix is mostly 0s and the diagonals are partial derivatives, which you can see below:\n",
    "\n",
    "<img src=\"vector_chain_rule.jpg\" width=\"600\" height=\"480\" />\n",
    "\n",
    "\n",
    "I think it's appropriate to insert the following gif of the mind being blown [11]:\n",
    "\n",
    "<img src=\"mind_blown.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Descent\n",
    "\n",
    "\n",
    "To get a nice overview, first checkout this video:\n",
    "[Gradient Descent Video](https://youtu.be/5u0jaA3qAGk?t=33s)\n",
    "\n",
    "\n",
    "We learned in Notebook 00 that the major goal for learning a machine learning model is to find the optimal set of weights that minimizes the loss function we define. One way to do this could be to randomly search the set of weights but the space is high dimensionsal and this search would be slow [2].\n",
    "\n",
    "A better way to find the optimal set of weights is to use _gradient descent_, which is an optimization algorithm that lets us use the gradient of the loss function with respect to the weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modified from http://cs231n.github.io/optimization-1/\n",
    "\n",
    "\"\"\"\n",
    "Vanilla Gradient Descent\n",
    "Our gradient descent algorithm is quite simply, for each training example we get, compute a weight update as follows:\n",
    "weights += learning_rate * gradient of weights with respect to loss function\n",
    "our gradient has the same dimensions as the weights vector (or matrix) itself\n",
    "\"\"\"\n",
    "\n",
    "# NOTE: this code sample won't work. Just meant to illustrate algorithm\n",
    "while True:\n",
    "  weights_gradient = evaluate_gradient(loss_function, data, weights)\n",
    "  weights += - learning_rate * weights_gradient # perform parameter update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"vanilla\" gradient descent is inefficient because a single update of the weights results in us having to process over all the training examples (captured by the variable data) above. Instead, we can do what's known as \"mini-batch\" gradient descent, which samples a small amount of training examples to perform each update.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9a63b8231d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# in current state of the art ConvNets, a typical batch contains 256 examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# this batch is then used to perform a parameter update:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mdata_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mweights_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweights_grad\u001b[0m \u001b[0;31m# perform parameter update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Borrowed from http://cs231n.github.io/optimization-1/\n",
    "\n",
    "\"\"\"\n",
    "Vanilla Minibatch Gradient Descent\n",
    "\"\"\"\n",
    "\n",
    "# NOTE: this code sample won't work. Just meant to illustrate algorithm\n",
    "while True:\n",
    "  # in current state of the art ConvNets, a typical batch contains 256 examples\n",
    "  # this batch is then used to perform a parameter update:\n",
    "  data_batch = sample_training_data(data, 256)\n",
    "  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)\n",
    "  weights += - step_size * weights_grad # perform parameter update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below uses a good analogy of finding the path down a hill to illustrate gradient descent [12]:\n",
    "\n",
    "<img src=\"gradient_descent_analogy.jpg\" width=\"800\" height=\"640\" />\n",
    "\n",
    "\n",
    "Let's us the example of Linear regression with Mean squared error cost function (since the gradient is easy to compute) to illustrate gradient descent:\n",
    "\n",
    "<img src=\"linear_regression_gradient.jpg\" width=\"1600\" height=\"1280\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Below we will use the example of a loss (cost) function for linear regression, which has the equation\n",
    "# y = m * x + b  where m = a vector of weights\n",
    "# Mean Squared Error cost function for y = mx + b\n",
    "\n",
    "# From http://wiki.fast.ai/index.php/Gradient_Descent\n",
    "def cost_function(x, y, m, b):\n",
    "  N = len(x)\n",
    "  total_error = 0.0\n",
    "  for i in range(N):\n",
    "    total_error += (y[i] - (m*x[i] + b))**2\n",
    "  return total_error / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From http://wiki.fast.ai/index.php/Gradient_Descent\n",
    "def update_weights(m, b, X, Y, learning_rate):\n",
    "  m_deriv = 0\n",
    "  b_deriv = 0\n",
    "  N = len(X)\n",
    "  for i in range(N):\n",
    "    # Calculate partial derivatives\n",
    "    # -2x(y - (mx + b))\n",
    "    m_deriv += -2*X[i] * (Y[i] - (m*X[i] + b))\n",
    "        \n",
    "    # -2(y - (mx + b))\n",
    "    b_deriv += -2*(Y[i] - (m*X[i] + b))\n",
    "\n",
    "  m += -learning_rate * (m_deriv / float(N)) \n",
    "  b += -learning_rate * (b_deriv / float(N))\n",
    "\n",
    "  return m, b\n",
    "\n",
    "# update_weights is just one iteration of gradient descent\n",
    "# one iteration requires a prediction for *each* instance in the training dataset since we are computing\n",
    "# m*X[i] + b\n",
    "# We will need to either keep going until some set number of iterations or until there is little improvement\n",
    "# in terms of the cost function from the previous iteration.\n",
    "# More on this here: https://stats.stackexchange.com/questions/33136/how-to-define-the-termination-condition-for-gradient-descent\n",
    "# Deep learning libraries run some kind of gradient descent under the covers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Regularization\n",
    "\n",
    "\n",
    "With any loss function, we are presented with an issue. Let's say you found an optimal set of weights that minimize the loss based on the training example data. As explained in [2], \"the issue is that this set of W is not necessarily unique: there might be many similar W that correctly classify the examples. One easy way to see this is that if some parameters W correctly classify all examples (so loss is zero for each example), then any multiple of these parameters λW where λ>1 will also give zero loss because this transformation uniformly stretches all score magnitudes and hence also their absolute differences.\"\n",
    "\n",
    "Thus, we need to come up with a _regularization penalty_ that is a function of our weights[2]:\n",
    "\n",
    "<img src=\"regularization_1.jpg\" width=\"800\" height=\"640\" />\n",
    "\n",
    "which results our loss function being decomposed into _data loss_ and _regularization loss_ [2]:\n",
    "\n",
    "<img src=\"regularization_2.jpg\" width=\"800\" height=\"640\" />\n",
    "\n",
    "In the next section, we will see regularization techniques such as dropout used in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. References\n",
    "\n",
    "<pre>\n",
    "  [1] Fast.ai (http://course.fast.ai/)  \n",
    "  [2] CS231N (http://cs231n.github.io/)  \n",
    "  [3] CS224D (http://cs224d.stanford.edu/syllabus.html)  \n",
    "  [4] Hands on Machine Learning (https://github.com/ageron/handson-ml)  \n",
    "  [5] Deep learning with Python Notebooks (https://github.com/fchollet/deep-learning-with-python-notebooks)  \n",
    "  [6] Deep learning by Goodfellow et. al (http://www.deeplearningbook.org/)  \n",
    "  [7] Neural networks online book (http://neuralnetworksanddeeplearning.com/)\n",
    "  [8] Vector Norms https://machinelearningmastery.com/vector-norms-machine-learning/\n",
    "  [9] The Matrix Calculus You Need For Deep Learning https://arxiv.org/pdf/1802.01528.pdf\n",
    "  [10] Practical Guide to Matrix Calculus for Deep Learning http://www.psi.toronto.edu/~andrew/papers/matrix_calculus_for_learning.pdf\n",
    "  [11] https://giphy.com/explore/mind-blown\n",
    "  [12] http://wiki.fast.ai/index.php/Gradient_Descent\n",
    "</pre>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
